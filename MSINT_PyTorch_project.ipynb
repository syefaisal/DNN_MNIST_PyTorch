{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a neural network using PyTorch\n",
    "* For this exercise, we will be using the famous MNIST dataset [5], \n",
    "* which is a sequence of images of handwritten postcode digits, zero through nine, with corresponding labels. \n",
    "* The MNIST dataset consists of 60,000 training samples and 10,000 test samples, where each sample is a grayscale image with 28 x 28 pixels. \n",
    "* PyTorch also provides the MNIST dataset under its Dataset module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./MNSIT_neural_achitecture.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "source": [
    "<img src=\"./MNIST_NN_Left.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./MNIST_NN_Right.png\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # 1-channel input, a 16-channel output, a kernel size of 3, and a stride of 1\n",
    "        self.cn1 = nn.Conv2d(1,16,3,1)\n",
    "        # 16-channel input, a 32-channel output, a kernel size of 3, and a stride of 1\n",
    "        self.cn2 = nn.Conv2d(16,32,3,1)\n",
    "        self.dp1 = nn.Dropout2d(0.10)\n",
    "        self.dp2 = nn.Dropout2d(0.25)\n",
    "        self.fc1 = nn.Linear(4608,64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.cn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x,2)\n",
    "        x = self.dp1(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dp2(x)\n",
    "        x = self.fc2(x)\n",
    "        op = F.log_softmax(x,dim=1)\n",
    "        return op\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training and inference routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_dataloader, optim, epoch):\n",
    "    model.train()\n",
    "    for b_i, (X, y) in enumerate(train_dataloader):\n",
    "        X,y = X.to(device), y.to(device)  # X is the image, y is the label\n",
    "        optim.zero_grad()  # zero the gradient buffer\n",
    "        pred_prob = model(X) # forward pass\n",
    "        loss = F.nll_loss(pred_prob, y) # calculate loss between the model prediction and the ground truth\n",
    "\n",
    "        loss.backward() # backpropagation\n",
    "        optim.step() # update weights\n",
    "        if b_i%10 == 0:    # prints training logs every 10 batches\n",
    "            print('epoch:{} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, b_i*len(X),\n",
    "                len(train_dataloader.dataset),\n",
    "                100.*b_i/len(train_dataloader),\n",
    "                loss.item())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_dataloader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    success = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred_prob = model(X)\n",
    "            # l\n",
    "            loss += F.nll_loss(pred_prob, y, reduction='sum').item()\n",
    "\n",
    "            pred = pred_prob.argmax(dim=1, keepdim=True)\n",
    "            success += pred.eq(y.view_as(pred)).sum().item()\n",
    "    loss /= len(test_dataloader.dataset)\n",
    "    print('\\nTest dataset: Overall Loss: {:.4f}, \\\n",
    "          Overall Accuracy: {}/{} ({:.0f}%)\\n'.format(loss, \n",
    "        success, len(test_dataloader.dataset), \n",
    "        100. * success / len(test_dataloader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:01<00:00, 5734921.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 542669.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:02<00:00, 700520.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 2527601.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                  transform=transforms.Compose([\n",
    "                      transforms.ToTensor(),\n",
    "                      transforms.Normalize((0.1302,), (0.3069,))])),\n",
    "                      batch_size=32,\n",
    "                      shuffle=True)\n",
    "test_dataloader = DataLoader.DataLoader(\n",
    "    datasets.MNIST('../data', train=False,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1302,),\n",
    "                                            (0.3069,))\n",
    "                   ])),\n",
    "    batch_size=500, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cpu\")\n",
    "model = ConvNet()\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 [0/60000 (0%)]\tLoss: 0.006781\n",
      "epoch:1 [320/60000 (1%)]\tLoss: 0.077179\n",
      "epoch:1 [640/60000 (1%)]\tLoss: 0.014905\n",
      "epoch:1 [960/60000 (2%)]\tLoss: 0.008559\n",
      "epoch:1 [1280/60000 (2%)]\tLoss: 0.055985\n",
      "epoch:1 [1600/60000 (3%)]\tLoss: 0.017430\n",
      "epoch:1 [1920/60000 (3%)]\tLoss: 0.089468\n",
      "epoch:1 [2240/60000 (4%)]\tLoss: 0.034433\n",
      "epoch:1 [2560/60000 (4%)]\tLoss: 0.057628\n",
      "epoch:1 [2880/60000 (5%)]\tLoss: 0.059608\n",
      "epoch:1 [3200/60000 (5%)]\tLoss: 0.029028\n",
      "epoch:1 [3520/60000 (6%)]\tLoss: 0.011429\n",
      "epoch:1 [3840/60000 (6%)]\tLoss: 0.051819\n",
      "epoch:1 [4160/60000 (7%)]\tLoss: 0.167144\n",
      "epoch:1 [4480/60000 (7%)]\tLoss: 0.034029\n",
      "epoch:1 [4800/60000 (8%)]\tLoss: 0.053237\n",
      "epoch:1 [5120/60000 (9%)]\tLoss: 0.012299\n",
      "epoch:1 [5440/60000 (9%)]\tLoss: 0.020151\n",
      "epoch:1 [5760/60000 (10%)]\tLoss: 0.016187\n",
      "epoch:1 [6080/60000 (10%)]\tLoss: 0.025621\n",
      "epoch:1 [6400/60000 (11%)]\tLoss: 0.038528\n",
      "epoch:1 [6720/60000 (11%)]\tLoss: 0.112390\n",
      "epoch:1 [7040/60000 (12%)]\tLoss: 0.040238\n",
      "epoch:1 [7360/60000 (12%)]\tLoss: 0.012753\n",
      "epoch:1 [7680/60000 (13%)]\tLoss: 0.003145\n",
      "epoch:1 [8000/60000 (13%)]\tLoss: 0.391849\n",
      "epoch:1 [8320/60000 (14%)]\tLoss: 0.036845\n",
      "epoch:1 [8640/60000 (14%)]\tLoss: 0.073304\n",
      "epoch:1 [8960/60000 (15%)]\tLoss: 0.005965\n",
      "epoch:1 [9280/60000 (15%)]\tLoss: 0.141563\n",
      "epoch:1 [9600/60000 (16%)]\tLoss: 0.186421\n",
      "epoch:1 [9920/60000 (17%)]\tLoss: 0.069074\n",
      "epoch:1 [10240/60000 (17%)]\tLoss: 0.003797\n",
      "epoch:1 [10560/60000 (18%)]\tLoss: 0.053369\n",
      "epoch:1 [10880/60000 (18%)]\tLoss: 0.178895\n",
      "epoch:1 [11200/60000 (19%)]\tLoss: 0.007460\n",
      "epoch:1 [11520/60000 (19%)]\tLoss: 0.131530\n",
      "epoch:1 [11840/60000 (20%)]\tLoss: 0.029811\n",
      "epoch:1 [12160/60000 (20%)]\tLoss: 0.009566\n",
      "epoch:1 [12480/60000 (21%)]\tLoss: 0.019006\n",
      "epoch:1 [12800/60000 (21%)]\tLoss: 0.106488\n",
      "epoch:1 [13120/60000 (22%)]\tLoss: 0.028430\n",
      "epoch:1 [13440/60000 (22%)]\tLoss: 0.100325\n",
      "epoch:1 [13760/60000 (23%)]\tLoss: 0.010219\n",
      "epoch:1 [14080/60000 (23%)]\tLoss: 0.009206\n",
      "epoch:1 [14400/60000 (24%)]\tLoss: 0.021521\n",
      "epoch:1 [14720/60000 (25%)]\tLoss: 0.119933\n",
      "epoch:1 [15040/60000 (25%)]\tLoss: 0.030108\n",
      "epoch:1 [15360/60000 (26%)]\tLoss: 0.023544\n",
      "epoch:1 [15680/60000 (26%)]\tLoss: 0.021009\n",
      "epoch:1 [16000/60000 (27%)]\tLoss: 0.001010\n",
      "epoch:1 [16320/60000 (27%)]\tLoss: 0.021236\n",
      "epoch:1 [16640/60000 (28%)]\tLoss: 0.062795\n",
      "epoch:1 [16960/60000 (28%)]\tLoss: 0.060399\n",
      "epoch:1 [17280/60000 (29%)]\tLoss: 0.002965\n",
      "epoch:1 [17600/60000 (29%)]\tLoss: 0.003907\n",
      "epoch:1 [17920/60000 (30%)]\tLoss: 0.037526\n",
      "epoch:1 [18240/60000 (30%)]\tLoss: 0.020912\n",
      "epoch:1 [18560/60000 (31%)]\tLoss: 0.006756\n",
      "epoch:1 [18880/60000 (31%)]\tLoss: 0.269671\n",
      "epoch:1 [19200/60000 (32%)]\tLoss: 0.114630\n",
      "epoch:1 [19520/60000 (33%)]\tLoss: 0.021449\n",
      "epoch:1 [19840/60000 (33%)]\tLoss: 0.013574\n",
      "epoch:1 [20160/60000 (34%)]\tLoss: 0.022516\n",
      "epoch:1 [20480/60000 (34%)]\tLoss: 0.023587\n",
      "epoch:1 [20800/60000 (35%)]\tLoss: 0.271112\n",
      "epoch:1 [21120/60000 (35%)]\tLoss: 0.016468\n",
      "epoch:1 [21440/60000 (36%)]\tLoss: 0.070667\n",
      "epoch:1 [21760/60000 (36%)]\tLoss: 0.001848\n",
      "epoch:1 [22080/60000 (37%)]\tLoss: 0.095504\n",
      "epoch:1 [22400/60000 (37%)]\tLoss: 0.016826\n",
      "epoch:1 [22720/60000 (38%)]\tLoss: 0.038714\n",
      "epoch:1 [23040/60000 (38%)]\tLoss: 0.012734\n",
      "epoch:1 [23360/60000 (39%)]\tLoss: 0.060708\n",
      "epoch:1 [23680/60000 (39%)]\tLoss: 0.014562\n",
      "epoch:1 [24000/60000 (40%)]\tLoss: 0.019890\n",
      "epoch:1 [24320/60000 (41%)]\tLoss: 0.011664\n",
      "epoch:1 [24640/60000 (41%)]\tLoss: 0.008840\n",
      "epoch:1 [24960/60000 (42%)]\tLoss: 0.123225\n",
      "epoch:1 [25280/60000 (42%)]\tLoss: 0.250523\n",
      "epoch:1 [25600/60000 (43%)]\tLoss: 0.003654\n",
      "epoch:1 [25920/60000 (43%)]\tLoss: 0.107206\n",
      "epoch:1 [26240/60000 (44%)]\tLoss: 0.295869\n",
      "epoch:1 [26560/60000 (44%)]\tLoss: 0.032351\n",
      "epoch:1 [26880/60000 (45%)]\tLoss: 0.057990\n",
      "epoch:1 [27200/60000 (45%)]\tLoss: 0.119882\n",
      "epoch:1 [27520/60000 (46%)]\tLoss: 0.007176\n",
      "epoch:1 [27840/60000 (46%)]\tLoss: 0.024513\n",
      "epoch:1 [28160/60000 (47%)]\tLoss: 0.051991\n",
      "epoch:1 [28480/60000 (47%)]\tLoss: 0.013254\n",
      "epoch:1 [28800/60000 (48%)]\tLoss: 0.052590\n",
      "epoch:1 [29120/60000 (49%)]\tLoss: 0.037524\n",
      "epoch:1 [29440/60000 (49%)]\tLoss: 0.076909\n",
      "epoch:1 [29760/60000 (50%)]\tLoss: 0.064117\n",
      "epoch:1 [30080/60000 (50%)]\tLoss: 0.003280\n",
      "epoch:1 [30400/60000 (51%)]\tLoss: 0.014950\n",
      "epoch:1 [30720/60000 (51%)]\tLoss: 0.261985\n",
      "epoch:1 [31040/60000 (52%)]\tLoss: 0.048695\n",
      "epoch:1 [31360/60000 (52%)]\tLoss: 0.008629\n",
      "epoch:1 [31680/60000 (53%)]\tLoss: 0.020798\n",
      "epoch:1 [32000/60000 (53%)]\tLoss: 0.009828\n",
      "epoch:1 [32320/60000 (54%)]\tLoss: 0.036215\n",
      "epoch:1 [32640/60000 (54%)]\tLoss: 0.039891\n",
      "epoch:1 [32960/60000 (55%)]\tLoss: 0.082818\n",
      "epoch:1 [33280/60000 (55%)]\tLoss: 0.118895\n",
      "epoch:1 [33600/60000 (56%)]\tLoss: 0.024095\n",
      "epoch:1 [33920/60000 (57%)]\tLoss: 0.280152\n",
      "epoch:1 [34240/60000 (57%)]\tLoss: 0.035673\n",
      "epoch:1 [34560/60000 (58%)]\tLoss: 0.034716\n",
      "epoch:1 [34880/60000 (58%)]\tLoss: 0.003641\n",
      "epoch:1 [35200/60000 (59%)]\tLoss: 0.018647\n",
      "epoch:1 [35520/60000 (59%)]\tLoss: 0.021578\n",
      "epoch:1 [35840/60000 (60%)]\tLoss: 0.043159\n",
      "epoch:1 [36160/60000 (60%)]\tLoss: 0.012956\n",
      "epoch:1 [36480/60000 (61%)]\tLoss: 0.011557\n",
      "epoch:1 [36800/60000 (61%)]\tLoss: 0.203248\n",
      "epoch:1 [37120/60000 (62%)]\tLoss: 0.004488\n",
      "epoch:1 [37440/60000 (62%)]\tLoss: 0.364347\n",
      "epoch:1 [37760/60000 (63%)]\tLoss: 0.161754\n",
      "epoch:1 [38080/60000 (63%)]\tLoss: 0.102076\n",
      "epoch:1 [38400/60000 (64%)]\tLoss: 0.057211\n",
      "epoch:1 [38720/60000 (65%)]\tLoss: 0.016766\n",
      "epoch:1 [39040/60000 (65%)]\tLoss: 0.015148\n",
      "epoch:1 [39360/60000 (66%)]\tLoss: 0.024310\n",
      "epoch:1 [39680/60000 (66%)]\tLoss: 0.063673\n",
      "epoch:1 [40000/60000 (67%)]\tLoss: 0.042876\n",
      "epoch:1 [40320/60000 (67%)]\tLoss: 0.001472\n",
      "epoch:1 [40640/60000 (68%)]\tLoss: 0.014108\n",
      "epoch:1 [40960/60000 (68%)]\tLoss: 0.033450\n",
      "epoch:1 [41280/60000 (69%)]\tLoss: 0.004153\n",
      "epoch:1 [41600/60000 (69%)]\tLoss: 0.083036\n",
      "epoch:1 [41920/60000 (70%)]\tLoss: 0.065973\n",
      "epoch:1 [42240/60000 (70%)]\tLoss: 0.017763\n",
      "epoch:1 [42560/60000 (71%)]\tLoss: 0.004779\n",
      "epoch:1 [42880/60000 (71%)]\tLoss: 0.100674\n",
      "epoch:1 [43200/60000 (72%)]\tLoss: 0.023248\n",
      "epoch:1 [43520/60000 (73%)]\tLoss: 0.239733\n",
      "epoch:1 [43840/60000 (73%)]\tLoss: 0.161065\n",
      "epoch:1 [44160/60000 (74%)]\tLoss: 0.037083\n",
      "epoch:1 [44480/60000 (74%)]\tLoss: 0.041634\n",
      "epoch:1 [44800/60000 (75%)]\tLoss: 0.016124\n",
      "epoch:1 [45120/60000 (75%)]\tLoss: 0.041117\n",
      "epoch:1 [45440/60000 (76%)]\tLoss: 0.022556\n",
      "epoch:1 [45760/60000 (76%)]\tLoss: 0.006236\n",
      "epoch:1 [46080/60000 (77%)]\tLoss: 0.010794\n",
      "epoch:1 [46400/60000 (77%)]\tLoss: 0.002864\n",
      "epoch:1 [46720/60000 (78%)]\tLoss: 0.029713\n",
      "epoch:1 [47040/60000 (78%)]\tLoss: 0.018247\n",
      "epoch:1 [47360/60000 (79%)]\tLoss: 0.015221\n",
      "epoch:1 [47680/60000 (79%)]\tLoss: 0.016702\n",
      "epoch:1 [48000/60000 (80%)]\tLoss: 0.035808\n",
      "epoch:1 [48320/60000 (81%)]\tLoss: 0.003116\n",
      "epoch:1 [48640/60000 (81%)]\tLoss: 0.219244\n",
      "epoch:1 [48960/60000 (82%)]\tLoss: 0.047120\n",
      "epoch:1 [49280/60000 (82%)]\tLoss: 0.010283\n",
      "epoch:1 [49600/60000 (83%)]\tLoss: 0.002279\n",
      "epoch:1 [49920/60000 (83%)]\tLoss: 0.086765\n",
      "epoch:1 [50240/60000 (84%)]\tLoss: 0.014817\n",
      "epoch:1 [50560/60000 (84%)]\tLoss: 0.008276\n",
      "epoch:1 [50880/60000 (85%)]\tLoss: 0.008318\n",
      "epoch:1 [51200/60000 (85%)]\tLoss: 0.040022\n",
      "epoch:1 [51520/60000 (86%)]\tLoss: 0.014018\n",
      "epoch:1 [51840/60000 (86%)]\tLoss: 0.000700\n",
      "epoch:1 [52160/60000 (87%)]\tLoss: 0.031059\n",
      "epoch:1 [52480/60000 (87%)]\tLoss: 0.008738\n",
      "epoch:1 [52800/60000 (88%)]\tLoss: 0.005603\n",
      "epoch:1 [53120/60000 (89%)]\tLoss: 0.010560\n",
      "epoch:1 [53440/60000 (89%)]\tLoss: 0.039583\n",
      "epoch:1 [53760/60000 (90%)]\tLoss: 0.005903\n",
      "epoch:1 [54080/60000 (90%)]\tLoss: 0.037020\n",
      "epoch:1 [54400/60000 (91%)]\tLoss: 0.014085\n",
      "epoch:1 [54720/60000 (91%)]\tLoss: 0.003659\n",
      "epoch:1 [55040/60000 (92%)]\tLoss: 0.023759\n",
      "epoch:1 [55360/60000 (92%)]\tLoss: 0.136321\n",
      "epoch:1 [55680/60000 (93%)]\tLoss: 0.111829\n",
      "epoch:1 [56000/60000 (93%)]\tLoss: 0.187884\n",
      "epoch:1 [56320/60000 (94%)]\tLoss: 0.193843\n",
      "epoch:1 [56640/60000 (94%)]\tLoss: 0.019067\n",
      "epoch:1 [56960/60000 (95%)]\tLoss: 0.069901\n",
      "epoch:1 [57280/60000 (95%)]\tLoss: 0.024103\n",
      "epoch:1 [57600/60000 (96%)]\tLoss: 0.136327\n",
      "epoch:1 [57920/60000 (97%)]\tLoss: 0.401399\n",
      "epoch:1 [58240/60000 (97%)]\tLoss: 0.014577\n",
      "epoch:1 [58560/60000 (98%)]\tLoss: 0.169891\n",
      "epoch:1 [58880/60000 (98%)]\tLoss: 0.004826\n",
      "epoch:1 [59200/60000 (99%)]\tLoss: 0.009950\n",
      "epoch:1 [59520/60000 (99%)]\tLoss: 0.064283\n",
      "epoch:1 [59840/60000 (100%)]\tLoss: 0.010565\n",
      "\n",
      "Test dataset: Overall Loss: 0.0404,           Overall Accuracy: 9871/10000 (99%)\n",
      "\n",
      "epoch:2 [0/60000 (0%)]\tLoss: 0.021610\n",
      "epoch:2 [320/60000 (1%)]\tLoss: 0.076510\n",
      "epoch:2 [640/60000 (1%)]\tLoss: 0.057664\n",
      "epoch:2 [960/60000 (2%)]\tLoss: 0.029883\n",
      "epoch:2 [1280/60000 (2%)]\tLoss: 0.015751\n",
      "epoch:2 [1600/60000 (3%)]\tLoss: 0.025503\n",
      "epoch:2 [1920/60000 (3%)]\tLoss: 0.007863\n",
      "epoch:2 [2240/60000 (4%)]\tLoss: 0.001483\n",
      "epoch:2 [2560/60000 (4%)]\tLoss: 0.000835\n",
      "epoch:2 [2880/60000 (5%)]\tLoss: 0.005705\n",
      "epoch:2 [3200/60000 (5%)]\tLoss: 0.002386\n",
      "epoch:2 [3520/60000 (6%)]\tLoss: 0.126907\n",
      "epoch:2 [3840/60000 (6%)]\tLoss: 0.008719\n",
      "epoch:2 [4160/60000 (7%)]\tLoss: 0.182472\n",
      "epoch:2 [4480/60000 (7%)]\tLoss: 0.155937\n",
      "epoch:2 [4800/60000 (8%)]\tLoss: 0.004745\n",
      "epoch:2 [5120/60000 (9%)]\tLoss: 0.127833\n",
      "epoch:2 [5440/60000 (9%)]\tLoss: 0.056110\n",
      "epoch:2 [5760/60000 (10%)]\tLoss: 0.029731\n",
      "epoch:2 [6080/60000 (10%)]\tLoss: 0.016506\n",
      "epoch:2 [6400/60000 (11%)]\tLoss: 0.032846\n",
      "epoch:2 [6720/60000 (11%)]\tLoss: 0.008778\n",
      "epoch:2 [7040/60000 (12%)]\tLoss: 0.023838\n",
      "epoch:2 [7360/60000 (12%)]\tLoss: 0.022599\n",
      "epoch:2 [7680/60000 (13%)]\tLoss: 0.121880\n",
      "epoch:2 [8000/60000 (13%)]\tLoss: 0.300719\n",
      "epoch:2 [8320/60000 (14%)]\tLoss: 0.211576\n",
      "epoch:2 [8640/60000 (14%)]\tLoss: 0.013573\n",
      "epoch:2 [8960/60000 (15%)]\tLoss: 0.004246\n",
      "epoch:2 [9280/60000 (15%)]\tLoss: 0.102329\n",
      "epoch:2 [9600/60000 (16%)]\tLoss: 0.009639\n",
      "epoch:2 [9920/60000 (17%)]\tLoss: 0.115986\n",
      "epoch:2 [10240/60000 (17%)]\tLoss: 0.126511\n",
      "epoch:2 [10560/60000 (18%)]\tLoss: 0.001103\n",
      "epoch:2 [10880/60000 (18%)]\tLoss: 0.001025\n",
      "epoch:2 [11200/60000 (19%)]\tLoss: 0.127359\n",
      "epoch:2 [11520/60000 (19%)]\tLoss: 0.040455\n",
      "epoch:2 [11840/60000 (20%)]\tLoss: 0.008185\n",
      "epoch:2 [12160/60000 (20%)]\tLoss: 0.015129\n",
      "epoch:2 [12480/60000 (21%)]\tLoss: 0.001665\n",
      "epoch:2 [12800/60000 (21%)]\tLoss: 0.049810\n",
      "epoch:2 [13120/60000 (22%)]\tLoss: 0.003276\n",
      "epoch:2 [13440/60000 (22%)]\tLoss: 0.006312\n",
      "epoch:2 [13760/60000 (23%)]\tLoss: 0.055460\n",
      "epoch:2 [14080/60000 (23%)]\tLoss: 0.048100\n",
      "epoch:2 [14400/60000 (24%)]\tLoss: 0.062622\n",
      "epoch:2 [14720/60000 (25%)]\tLoss: 0.151792\n",
      "epoch:2 [15040/60000 (25%)]\tLoss: 0.005671\n",
      "epoch:2 [15360/60000 (26%)]\tLoss: 0.170346\n",
      "epoch:2 [15680/60000 (26%)]\tLoss: 0.006572\n",
      "epoch:2 [16000/60000 (27%)]\tLoss: 0.134537\n",
      "epoch:2 [16320/60000 (27%)]\tLoss: 0.000215\n",
      "epoch:2 [16640/60000 (28%)]\tLoss: 0.026160\n",
      "epoch:2 [16960/60000 (28%)]\tLoss: 0.052194\n",
      "epoch:2 [17280/60000 (29%)]\tLoss: 0.088821\n",
      "epoch:2 [17600/60000 (29%)]\tLoss: 0.006936\n",
      "epoch:2 [17920/60000 (30%)]\tLoss: 0.025036\n",
      "epoch:2 [18240/60000 (30%)]\tLoss: 0.003858\n",
      "epoch:2 [18560/60000 (31%)]\tLoss: 0.057639\n",
      "epoch:2 [18880/60000 (31%)]\tLoss: 0.008103\n",
      "epoch:2 [19200/60000 (32%)]\tLoss: 0.009282\n",
      "epoch:2 [19520/60000 (33%)]\tLoss: 0.013285\n",
      "epoch:2 [19840/60000 (33%)]\tLoss: 0.138349\n",
      "epoch:2 [20160/60000 (34%)]\tLoss: 0.005334\n",
      "epoch:2 [20480/60000 (34%)]\tLoss: 0.015196\n",
      "epoch:2 [20800/60000 (35%)]\tLoss: 0.025625\n",
      "epoch:2 [21120/60000 (35%)]\tLoss: 0.017442\n",
      "epoch:2 [21440/60000 (36%)]\tLoss: 0.085653\n",
      "epoch:2 [21760/60000 (36%)]\tLoss: 0.065940\n",
      "epoch:2 [22080/60000 (37%)]\tLoss: 0.001741\n",
      "epoch:2 [22400/60000 (37%)]\tLoss: 0.049264\n",
      "epoch:2 [22720/60000 (38%)]\tLoss: 0.040530\n",
      "epoch:2 [23040/60000 (38%)]\tLoss: 0.002581\n",
      "epoch:2 [23360/60000 (39%)]\tLoss: 0.001883\n",
      "epoch:2 [23680/60000 (39%)]\tLoss: 0.056694\n",
      "epoch:2 [24000/60000 (40%)]\tLoss: 0.015851\n",
      "epoch:2 [24320/60000 (41%)]\tLoss: 0.029350\n",
      "epoch:2 [24640/60000 (41%)]\tLoss: 0.033421\n",
      "epoch:2 [24960/60000 (42%)]\tLoss: 0.007003\n",
      "epoch:2 [25280/60000 (42%)]\tLoss: 0.008864\n",
      "epoch:2 [25600/60000 (43%)]\tLoss: 0.052225\n",
      "epoch:2 [25920/60000 (43%)]\tLoss: 0.044598\n",
      "epoch:2 [26240/60000 (44%)]\tLoss: 0.022976\n",
      "epoch:2 [26560/60000 (44%)]\tLoss: 0.003342\n",
      "epoch:2 [26880/60000 (45%)]\tLoss: 0.058907\n",
      "epoch:2 [27200/60000 (45%)]\tLoss: 0.004935\n",
      "epoch:2 [27520/60000 (46%)]\tLoss: 0.018591\n",
      "epoch:2 [27840/60000 (46%)]\tLoss: 0.004675\n",
      "epoch:2 [28160/60000 (47%)]\tLoss: 0.057641\n",
      "epoch:2 [28480/60000 (47%)]\tLoss: 0.439306\n",
      "epoch:2 [28800/60000 (48%)]\tLoss: 0.018964\n",
      "epoch:2 [29120/60000 (49%)]\tLoss: 0.017207\n",
      "epoch:2 [29440/60000 (49%)]\tLoss: 0.095589\n",
      "epoch:2 [29760/60000 (50%)]\tLoss: 0.007925\n",
      "epoch:2 [30080/60000 (50%)]\tLoss: 0.006174\n",
      "epoch:2 [30400/60000 (51%)]\tLoss: 0.026871\n",
      "epoch:2 [30720/60000 (51%)]\tLoss: 0.158559\n",
      "epoch:2 [31040/60000 (52%)]\tLoss: 0.128056\n",
      "epoch:2 [31360/60000 (52%)]\tLoss: 0.067195\n",
      "epoch:2 [31680/60000 (53%)]\tLoss: 0.004140\n",
      "epoch:2 [32000/60000 (53%)]\tLoss: 0.189802\n",
      "epoch:2 [32320/60000 (54%)]\tLoss: 0.009782\n",
      "epoch:2 [32640/60000 (54%)]\tLoss: 0.000985\n",
      "epoch:2 [32960/60000 (55%)]\tLoss: 0.062115\n",
      "epoch:2 [33280/60000 (55%)]\tLoss: 0.056903\n",
      "epoch:2 [33600/60000 (56%)]\tLoss: 0.085047\n",
      "epoch:2 [33920/60000 (57%)]\tLoss: 0.045769\n",
      "epoch:2 [34240/60000 (57%)]\tLoss: 0.001794\n",
      "epoch:2 [34560/60000 (58%)]\tLoss: 0.147596\n",
      "epoch:2 [34880/60000 (58%)]\tLoss: 0.000759\n",
      "epoch:2 [35200/60000 (59%)]\tLoss: 0.214002\n",
      "epoch:2 [35520/60000 (59%)]\tLoss: 0.003190\n",
      "epoch:2 [35840/60000 (60%)]\tLoss: 0.212449\n",
      "epoch:2 [36160/60000 (60%)]\tLoss: 0.071904\n",
      "epoch:2 [36480/60000 (61%)]\tLoss: 0.185621\n",
      "epoch:2 [36800/60000 (61%)]\tLoss: 0.001231\n",
      "epoch:2 [37120/60000 (62%)]\tLoss: 0.016959\n",
      "epoch:2 [37440/60000 (62%)]\tLoss: 0.000978\n",
      "epoch:2 [37760/60000 (63%)]\tLoss: 0.000403\n",
      "epoch:2 [38080/60000 (63%)]\tLoss: 0.000191\n",
      "epoch:2 [38400/60000 (64%)]\tLoss: 0.041114\n",
      "epoch:2 [38720/60000 (65%)]\tLoss: 0.117709\n",
      "epoch:2 [39040/60000 (65%)]\tLoss: 0.212828\n",
      "epoch:2 [39360/60000 (66%)]\tLoss: 0.076657\n",
      "epoch:2 [39680/60000 (66%)]\tLoss: 0.003735\n",
      "epoch:2 [40000/60000 (67%)]\tLoss: 0.126427\n",
      "epoch:2 [40320/60000 (67%)]\tLoss: 0.003147\n",
      "epoch:2 [40640/60000 (68%)]\tLoss: 0.030868\n",
      "epoch:2 [40960/60000 (68%)]\tLoss: 0.008022\n",
      "epoch:2 [41280/60000 (69%)]\tLoss: 0.185443\n",
      "epoch:2 [41600/60000 (69%)]\tLoss: 0.089445\n",
      "epoch:2 [41920/60000 (70%)]\tLoss: 0.008414\n",
      "epoch:2 [42240/60000 (70%)]\tLoss: 0.001291\n",
      "epoch:2 [42560/60000 (71%)]\tLoss: 0.077535\n",
      "epoch:2 [42880/60000 (71%)]\tLoss: 0.035668\n",
      "epoch:2 [43200/60000 (72%)]\tLoss: 0.000599\n",
      "epoch:2 [43520/60000 (73%)]\tLoss: 0.011563\n",
      "epoch:2 [43840/60000 (73%)]\tLoss: 0.012495\n",
      "epoch:2 [44160/60000 (74%)]\tLoss: 0.036420\n",
      "epoch:2 [44480/60000 (74%)]\tLoss: 0.109669\n",
      "epoch:2 [44800/60000 (75%)]\tLoss: 0.007027\n",
      "epoch:2 [45120/60000 (75%)]\tLoss: 0.035499\n",
      "epoch:2 [45440/60000 (76%)]\tLoss: 0.003800\n",
      "epoch:2 [45760/60000 (76%)]\tLoss: 0.059613\n",
      "epoch:2 [46080/60000 (77%)]\tLoss: 0.022973\n",
      "epoch:2 [46400/60000 (77%)]\tLoss: 0.134641\n",
      "epoch:2 [46720/60000 (78%)]\tLoss: 0.077616\n",
      "epoch:2 [47040/60000 (78%)]\tLoss: 0.007549\n",
      "epoch:2 [47360/60000 (79%)]\tLoss: 0.022259\n",
      "epoch:2 [47680/60000 (79%)]\tLoss: 0.023957\n",
      "epoch:2 [48000/60000 (80%)]\tLoss: 0.041102\n",
      "epoch:2 [48320/60000 (81%)]\tLoss: 0.145885\n",
      "epoch:2 [48640/60000 (81%)]\tLoss: 0.108167\n",
      "epoch:2 [48960/60000 (82%)]\tLoss: 0.000720\n",
      "epoch:2 [49280/60000 (82%)]\tLoss: 0.001036\n",
      "epoch:2 [49600/60000 (83%)]\tLoss: 0.038916\n",
      "epoch:2 [49920/60000 (83%)]\tLoss: 0.042477\n",
      "epoch:2 [50240/60000 (84%)]\tLoss: 0.007126\n",
      "epoch:2 [50560/60000 (84%)]\tLoss: 0.007915\n",
      "epoch:2 [50880/60000 (85%)]\tLoss: 0.098826\n",
      "epoch:2 [51200/60000 (85%)]\tLoss: 0.118302\n",
      "epoch:2 [51520/60000 (86%)]\tLoss: 0.049835\n",
      "epoch:2 [51840/60000 (86%)]\tLoss: 0.214067\n",
      "epoch:2 [52160/60000 (87%)]\tLoss: 0.026400\n",
      "epoch:2 [52480/60000 (87%)]\tLoss: 0.015286\n",
      "epoch:2 [52800/60000 (88%)]\tLoss: 0.041908\n",
      "epoch:2 [53120/60000 (89%)]\tLoss: 0.007080\n",
      "epoch:2 [53440/60000 (89%)]\tLoss: 0.151936\n",
      "epoch:2 [53760/60000 (90%)]\tLoss: 0.020219\n",
      "epoch:2 [54080/60000 (90%)]\tLoss: 0.141785\n",
      "epoch:2 [54400/60000 (91%)]\tLoss: 0.038310\n",
      "epoch:2 [54720/60000 (91%)]\tLoss: 0.083477\n",
      "epoch:2 [55040/60000 (92%)]\tLoss: 0.371622\n",
      "epoch:2 [55360/60000 (92%)]\tLoss: 0.010881\n",
      "epoch:2 [55680/60000 (93%)]\tLoss: 0.105089\n",
      "epoch:2 [56000/60000 (93%)]\tLoss: 0.000621\n",
      "epoch:2 [56320/60000 (94%)]\tLoss: 0.011044\n",
      "epoch:2 [56640/60000 (94%)]\tLoss: 0.289937\n",
      "epoch:2 [56960/60000 (95%)]\tLoss: 0.144716\n",
      "epoch:2 [57280/60000 (95%)]\tLoss: 0.002383\n",
      "epoch:2 [57600/60000 (96%)]\tLoss: 0.002197\n",
      "epoch:2 [57920/60000 (97%)]\tLoss: 0.034910\n",
      "epoch:2 [58240/60000 (97%)]\tLoss: 0.012346\n",
      "epoch:2 [58560/60000 (98%)]\tLoss: 0.050884\n",
      "epoch:2 [58880/60000 (98%)]\tLoss: 0.016444\n",
      "epoch:2 [59200/60000 (99%)]\tLoss: 0.027423\n",
      "epoch:2 [59520/60000 (99%)]\tLoss: 0.078193\n",
      "epoch:2 [59840/60000 (100%)]\tLoss: 0.159769\n",
      "\n",
      "Test dataset: Overall Loss: 0.0420,           Overall Accuracy: 9862/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,3):\n",
    "    train(model, device, train_dataloader, optimizer, epoch)\n",
    "    test(model, device, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run inference on trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_samples = enumerate(test_dataloader)\n",
    "b_i, (sample_data, sample_targets) = next(test_samples) \n",
    "\n",
    "# plt.imshow(sample_data[0][0], cmap='gray', interpolation='none')\n",
    "plt.imshow(sample_data[12][0], cmap='gray', interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: 9\n",
      "Ground truth is : 9\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model prediction: {model(sample_data).data.max(1)[1][12]}\")\n",
    "print(f\"Ground truth is : {sample_targets[12]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
